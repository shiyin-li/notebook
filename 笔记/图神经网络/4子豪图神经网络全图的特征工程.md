## 全图的特征工程

### Graph Kernal

![image-20230406171851047](../../assets/4子豪图神经网络全图的特征工程/image-20230406171851047.png)

![image-20230406172033533](../../assets/4子豪图神经网络全图的特征工程/image-20230406172033533.png)



![image-20230406172613541](../../assets/4子豪图神经网络全图的特征工程/image-20230406172613541.png)

和结点邻域的Graphlet 不一样 这个是全部的结点 可以有孤立的结点

![image-20230406172707570](../../assets/4子豪图神经网络全图的特征工程/image-20230406172707570.png)

#### 数量积得出的kernal是个标量  可以反映两个图是否足够相近 有时需要归一化处理

![image-20230406173110702](../../assets/4子豪图神经网络全图的特征工程/image-20230406173110702.png)

#### 为何不常用用这种算法？  因为需要的算力太大  时间复杂度太高 引入下个算法

![image-20230406173550694](../../assets/4子豪图神经网络全图的特征工程/image-20230406173550694.png)



### Weisfeiler-Lehman Kernel （维斯菲ler 雷曼 ） 又叫做 bag-of-colors

![image-20230406173752627](../../assets/4子豪图神经网络全图的特征工程/image-20230406173752627.png)

#### 怎么做

![image-20230406174127034](../../assets/4子豪图神经网络全图的特征工程/image-20230406174127034.png)

![image-20230406174145471](../../assets/4子豪图神经网络全图的特征工程/image-20230406174145471.png)

再来一遍 

![image-20230406174238975](../../assets/4子豪图神经网络全图的特征工程/image-20230406174238975.png)

![image-20230406174309557](../../assets/4子豪图神经网络全图的特征工程/image-20230406174309557.png)

![image-20230406174536806](../../assets/4子豪图神经网络全图的特征工程/image-20230406174536806.png)



求kernal ![image-20230406174659643](../../assets/4子豪图神经网络全图的特征工程/image-20230406174659643.png)

重复多少次停止呢 ？

![image-20230406174807667](../../assets/4子豪图神经网络全图的特征工程/image-20230406174807667.png)

与颜色线性相关 与连接个数线性相关  与结点线性相关  相比于Graph kernal 快得多

![image-20230406174912760](../../assets/4子豪图神经网络全图的特征工程/image-20230406174912760.png)

### summary

![image-20230406195151504](../../assets/4子豪图神经网络全图的特征工程/image-20230406195151504.png)

#### kernal method 两张图（也可以是子图）进行数量积    kernal代表的是两张图的特征

kernal就可以当成ML的SVM的kernal函数

![image-20230406195528521](../../assets/4子豪图神经网络全图的特征工程/image-20230406195528521.png)

![image-20230406195758758](../../assets/4子豪图神经网络全图的特征工程/image-20230406195758758.png)

### 习题和阅读

