### GCN图卷积神经网络（最简单的图神经网络）

![image-20230415165451741](../../assets/12.子豪GCN/image-20230415165451741.png)

![image-20230415165546469](../../assets/12.子豪GCN/image-20230415165546469.png)

![image-20230415165645840](../../assets/12.子豪GCN/image-20230415165645840.png)

![image-20230415165723815](../../assets/12.子豪GCN/image-20230415165723815.png)

![image-20230415165751287](../../assets/12.子豪GCN/image-20230415165751287.png)

![image-20230415165806375](../../assets/12.子豪GCN/image-20230415165806375.png)

#### 图卷积神经网络 计算图

- 不能直接使用邻接矩阵输入神经网络 
- 不能使用CNN来得到embedding 
- 使用计算图的方法（使用消息传递）得到每个结点的embedding

![image-20230415165842731](../../assets/12.子豪GCN/image-20230415165842731.png)

![image-20230415165900818](../../assets/12.子豪GCN/image-20230415165900818.png)

![image-20230415170241695](../../assets/12.子豪GCN/image-20230415170241695.png)

![image-20230415170301944](../../assets/12.子豪GCN/image-20230415170301944.png)

![image-20230415170320642](../../assets/12.子豪GCN/image-20230415170320642.png)

![image-20230415170454431](../../assets/12.子豪GCN/image-20230415170454431.png)

![image-20230415170530731](../../assets/12.子豪GCN/image-20230415170530731.png)

![image-20230415170952590](../../assets/12.子豪GCN/image-20230415170952590.png)

![image-20230415171029657](../../assets/12.子豪GCN/image-20230415171029657.png)

![image-20230415171107718](../../assets/12.子豪GCN/image-20230415171107718.png)

``注：前向预测（损失函数）反向传播（求偏导调整权重）``

#### 图卷积神经网络  数学形式

![image-20230415171317715](../../assets/12.子豪GCN/image-20230415171317715.png)

![image-20230415172341717](../../assets/12.子豪GCN/image-20230415172341717.png)

``注：蓝框中的求平均操作 是order invariant 即与顺序无关``

![image-20230415173304316](../../assets/12.子豪GCN/image-20230415173304316.png)

**这个求平均的矩阵操作不明白**

![image-20230415173945745](../../assets/12.子豪GCN/image-20230415173945745.png)

![image-20230415174429137](../../assets/12.子豪GCN/image-20230415174429137.png)

##### 代码：引出Symmetric Normalized Matrix 幅值不会变化 并且能较好的表达出图中的连接关系

![image-20230415174725013](../../assets/12.子豪GCN/image-20230415174725013.png)

![image-20230415174801895](../../assets/12.子豪GCN/image-20230415174801895.png)

![image-20230415175007657](../../assets/12.子豪GCN/image-20230415175007657.png)

![image-20230415175350825](../../assets/12.子豪GCN/image-20230415175350825.png)

![image-20230415175559720](../../assets/12.子豪GCN/image-20230415175559720.png)

![image-20230415175704170](../../assets/12.子豪GCN/image-20230415175704170.png)

![image-20230415181559439](../../assets/12.子豪GCN/image-20230415181559439.png)

##### 特征值特征向量的计算

![image-20230416084540904](../../assets/12.子豪GCN/image-20230416084540904.png)

![image-20230416084632643](../../assets/12.子豪GCN/image-20230416084632643.png)

再平域和普域中可以使用Laplace矩阵

![image-20230416084728127](../../assets/12.子豪GCN/image-20230416084728127.png)

![image-20230416084812772](../../assets/12.子豪GCN/image-20230416084812772.png)

![image-20230416084932097](../../assets/12.子豪GCN/image-20230416084932097.png)

![image-20230416085022628](../../assets/12.子豪GCN/image-20230416085022628.png)

![image-20230416085036113](../../assets/12.子豪GCN/image-20230416085036113.png)

#### 图卷积神经网络  计算图改进

![image-20230416085131618](../../assets/12.子豪GCN/image-20230416085131618.png)

##### 上面计算图的缺点

![image-20230416085231215](../../assets/12.子豪GCN/image-20230416085231215.png)

![image-20230416085253390](../../assets/12.子豪GCN/image-20230416085253390.png)

![image-20230416085341104](../../assets/12.子豪GCN/image-20230416085341104.png)

![image-20230416085412924](../../assets/12.子豪GCN/image-20230416085412924.png)

##### 计算图的最终形式

![image-20230416085617905](../../assets/12.子豪GCN/image-20230416085617905.png)

![image-20230416090233583](../../assets/12.子豪GCN/image-20230416090233583.png)

##### 可以使用两个权重 一个是对于外人的(Wk)  一个是对于自己的(Bk)

![image-20230416091037563](../../assets/12.子豪GCN/image-20230416091037563.png)

![image-20230416092111984](../../assets/12.子豪GCN/image-20230416092111984.png)

![image-20230416092150005](../../assets/12.子豪GCN/image-20230416092150005.png)

#### 如何训练图神经网络?

![image-20230416092307971](../../assets/12.子豪GCN/image-20230416092307971.png)

![image-20230416092414428](../../assets/12.子豪GCN/image-20230416092414428.png)

![image-20230416092502822](../../assets/12.子豪GCN/image-20230416092502822.png)

##### 监督学习：交叉熵损失函数

![image-20230416092723890](../../assets/12.子豪GCN/image-20230416092723890.png)

![image-20230416092825807](../../assets/12.子豪GCN/image-20230416092825807.png)

![image-20230416092933550](../../assets/12.子豪GCN/image-20230416092933550.png)

##### 无监督学习

![image-20230416094636124](../../assets/12.子豪GCN/image-20230416094636124.png)

#### 图神经网络相比传统方法的优点

![image-20230416094739801](../../assets/12.子豪GCN/image-20230416094739801.png)

![image-20230416100137118](../../assets/12.子豪GCN/image-20230416100137118.png)

![image-20230416100210833](../../assets/12.子豪GCN/image-20230416100210833.png)

![image-20230416100634877](../../assets/12.子豪GCN/image-20230416100634877.png)

![image-20230416100703221](../../assets/12.子豪GCN/image-20230416100703221.png)

![image-20230416100757709](../../assets/12.子豪GCN/image-20230416100757709.png)

![image-20230416101057149](../../assets/12.子豪GCN/image-20230416101057149.png)

![image-20230416101116729](../../assets/12.子豪GCN/image-20230416101116729.png)

![image-20230416101143428](../../assets/12.子豪GCN/image-20230416101143428.png)

![image-20230416101239110](../../assets/12.子豪GCN/image-20230416101239110.png)

![image-20230416101256838](../../assets/12.子豪GCN/image-20230416101256838.png)

![image-20230416101423473](../../assets/12.子豪GCN/image-20230416101423473.png)

![image-20230416101435835](../../assets/12.子豪GCN/image-20230416101435835.png)

![image-20230416101710465](../../assets/12.子豪GCN/image-20230416101710465.png)

![image-20230416101824612](../../assets/12.子豪GCN/image-20230416101824612.png)

![image-20230416101843237](../../assets/12.子豪GCN/image-20230416101843237.png)

#### 图神经网络和其它神经网络的区别

##### CNN

![image-20230416101959208](../../assets/12.子豪GCN/image-20230416101959208.png)

![image-20230416102052552](../../assets/12.子豪GCN/image-20230416102052552.png)

![image-20230416102255937](../../assets/12.子豪GCN/image-20230416102255937.png)

![image-20230416102401819](../../assets/12.子豪GCN/image-20230416102401819.png)

![image-20230416102423221](../../assets/12.子豪GCN/image-20230416102423221.png)

![image-20230416102527716](../../assets/12.子豪GCN/image-20230416102527716.png)

``注：1.CNN的卷积核是需要重新学习的，对于位置和顺序有要求，不是置换不变的``

``2.GNN的卷积核是由D-1/2 A D-1/2矩阵定义好的，不需要重新计算，具有置换不变性``

##### transformer

**每两个单词之间都有权重**

![image-20230416102957502](../../assets/12.子豪GCN/image-20230416102957502.png)

**注意力机制也可以当作一个全连接的图**

![image-20230416103123803](../../assets/12.子豪GCN/image-20230416103123803.png)

#### 复盘总结

![image-20230416103333642](../../assets/12.子豪GCN/image-20230416103333642.png)

![image-20230416103353754](../../assets/12.子豪GCN/image-20230416103353754.png)

##### 灵活处理

![image-20230416103544533](../../assets/12.子豪GCN/image-20230416103544533.png)

##### summary

![image-20230416103611046](../../assets/12.子豪GCN/image-20230416103611046.png)

![image-20230416103634106](../../assets/12.子豪GCN/image-20230416103634106.png)